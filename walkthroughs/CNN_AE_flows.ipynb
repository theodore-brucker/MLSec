{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder with CNN\n",
    "\n",
    "Current state of the 475 project that creates an Autoencoder with CNN layers\n",
    "Currently on a custom dataset that has packet captures from documented Malware and Benign applications  \n",
    "Trains on sequences of flows from CICIDS2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your dataset\n",
    "dataset_path = 'C:/Users/theob/Code/COS-475-Project/Dataset/CSE-CIC-IDS2018/Wednesday-14-02-2018_TrafficForML_CICFlowMeter.csv'\n",
    "dataset_path2 = 'C:/Users/theob/Code/COS-475-Project/Dataset/CSE-CIC-IDS2018/Friday-16-02-2018_TrafficForML_CICFlowMeter.csv'\n",
    "# Read in the dataset\n",
    "flows1 = pd.read_csv(dataset_path)\n",
    "flows2 = pd.read_csv(dataset_path2, low_memory=False)\n",
    "\n",
    "flows = pd.concat([flows1[:300000], flows2[:300000]], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the flow dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_dataframe(df):\n",
    "    initial_columns_count = df.shape[1]\n",
    "    initial_rows_count = df.shape[0]\n",
    "\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            # Use errors='coerce' to turn parsing errors into NaNs\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "    numeric_df = df.select_dtypes(include=[np.number])\n",
    "    df = numeric_df.loc[:, (numeric_df != 0).any(axis=0)]\n",
    "    df = df[~df.isin([np.inf, -np.inf]).any(axis=1)]\n",
    "    df = df[(df >= 0).all(axis=1)]\n",
    "\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    final_columns_count = df.shape[1]\n",
    "    final_rows_count = df.shape[0]\n",
    "\n",
    "    print(f\"Initial number of columns: {initial_columns_count}, final number of columns: {final_columns_count}\")\n",
    "    print(f\"Initial number of rows: {initial_rows_count}, final number of rows: {final_rows_count}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def encode_labels(labels):\n",
    "    # Converts a list of labels into integer format where each unique label is assigned a unique integer.\n",
    "    # Additionally, prints the total number of unique labels and the number of occurrences of each label.\n",
    "\n",
    "    # Create a dictionary to map each label to a unique integer\n",
    "    unique_labels = sorted(set(labels))\n",
    "    label_mapping = {label: i for i, label in enumerate(unique_labels)}\n",
    "\n",
    "    # Count occurrences of each label\n",
    "    label_counts = collections.Counter(labels)\n",
    "    \n",
    "    # Print the total number of unique labels and occurrences of each\n",
    "    print(f\"Total number of unique labels: {len(unique_labels)}\")\n",
    "    print(\"Occurrences of each label:\")\n",
    "    for label, count in sorted(label_counts.items(), key=lambda x: label_mapping[x[0]]):\n",
    "        print(f\"{label}: {count}\")\n",
    "\n",
    "    # Apply the mapping to the labels list to create the encoded labels list\n",
    "    encoded_labels = [label_mapping[label] for label in labels]\n",
    "\n",
    "    return encoded_labels\n",
    "\n",
    "# Encode and separate the labels from the features\n",
    "flows['Label'] = encode_labels(flows['Label'])\n",
    "\n",
    "# Clean the feature space and drop 5 columns to create a 64 feature shape\n",
    "flows_semi_reduced = clean_dataframe(flows.drop(['Timestamp', 'Active Std', 'Active Max',\n",
    "       'Active Min',], axis=1))\n",
    "\n",
    "\n",
    "flow_labels = flows_semi_reduced['Label']\n",
    "flows_reduced = flows_semi_reduced.drop(['Label'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply scalar before matrix creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def apply_minmax_scaler(dataframe):\n",
    "    # Create an instance of MinMaxScaler\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Fit the scaler to the data and transform it\n",
    "    scaled_data = scaler.fit_transform(dataframe)\n",
    "\n",
    "    # Convert the scaled array back to a DataFrame\n",
    "    scaled_dataframe = pd.DataFrame(scaled_data, columns=dataframe.columns)\n",
    "\n",
    "    return scaled_dataframe\n",
    "\n",
    "flows_scaled = flows_reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2D-ify with Triangle Area Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectors_to_matrices(df):\n",
    "    matrices = []\n",
    "    for index, vector in df.iterrows():  # Iterating correctly over rows\n",
    "        if pd.api.types.is_numeric_dtype(vector):  # Ensuring vector contains numeric data\n",
    "            # Convert the Series to a proper numeric type if not already\n",
    "            vector = vector.astype(float)\n",
    "            # Calculate the outer product of the vector with itself\n",
    "            matrix = np.outer(vector, vector)\n",
    "            matrices.append(matrix)\n",
    "    return matrices\n",
    "\n",
    "matrices = vectors_to_matrices(flows_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting the matrices to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "flow_tensors = [torch.tensor(matrix, dtype=torch.float32) for matrix in matrices]\n",
    "\n",
    "train_indices, test_indices = train_test_split(\n",
    "    np.arange(len(flow_labels)),  # create an index array\n",
    "    test_size=0.2,  # 20% of the data will be used for testing\n",
    "    random_state=42,  # seed for reproducibility\n",
    "    stratify=flow_labels  # preserve class distribution\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, indices, labels=None, augment=False):\n",
    "        self.data = torch.stack([data[i] for i in indices])\n",
    "        self.labels = torch.tensor([labels[i] for i in indices]) if labels is not None else None\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data_item = self.data[idx]\n",
    "        data_item = data_item.unsqueeze(0)  # This adds a channel dimension\n",
    "        if self.augment and (self.labels is not None and self.labels[idx] == 0):\n",
    "            data_item = self.augment_data(data_item)\n",
    "        return data_item, self.labels[idx] if self.labels is not None else data_item\n",
    "\n",
    "    def augment_data(self, data_item):\n",
    "        # Noise injection\n",
    "        noise = torch.randn_like(data_item) * 0.01  # Adjust noise level\n",
    "        data_item += noise\n",
    "        # Normalization\n",
    "        if torch.max(data_item) != torch.min(data_item):\n",
    "            data_item = (data_item - torch.min(data_item)) / (torch.max(data_item) - torch.min(data_item))\n",
    "        return data_item\n",
    "\n",
    "\n",
    "labels_array = np.array(flow_labels, dtype=np.int32)\n",
    "\n",
    "train_dataset = CustomDataset(flow_tensors, train_indices, labels=flow_labels)\n",
    "test_dataset = CustomDataset(flow_tensors, test_indices, labels=flow_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data, labels in train_loader:\n",
    "    input_width = data.shape[3]\n",
    "    print(\"Input batch shape from DataLoader:\", data.shape)\n",
    "    print(\"Labels batch shape from DataLoader:\", labels.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensure that cuda is available, else run on the CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if CUDA is available and set device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ConvSequenceAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvSequenceAutoencoder, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=8, kernel_size=(5, 5), padding=1, bias=True),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(5, 5), padding=1, bias=True),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=16, out_channels=8, kernel_size=(5, 5), bias=True),\n",
    "            nn.Sigmoid(),\n",
    "            nn.ConvTranspose2d(in_channels=8, out_channels=1, kernel_size=(5, 5), padding=2, bias=True),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "    \n",
    "model = ConvSequenceAutoencoder().to(device)\n",
    "optimizer = Adam(model.parameters(), lr=0.001, weight_decay=1e-5)  # L2 regularization\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.1)  # Learning rate decay\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test an input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_autoencoder():\n",
    "    # Create a sample input tensor of size (batch_size, channels, height, width)\n",
    "    # Example dimensions: 1 image, 1 channel (e.g., grayscale), 28x28 pixels\n",
    "    input_tensor = torch.randn(64, 1, 65, 65)\n",
    "    print(\"Input shape:\", input_tensor.shape)\n",
    "    \n",
    "    # Initialize the model\n",
    "    model = ConvSequenceAutoencoder()\n",
    "    \n",
    "    # Forward the input tensor through the model\n",
    "    output_tensor = model(input_tensor)\n",
    "    print(\"Output shape:\", output_tensor.shape)\n",
    "\n",
    "# Call the test function to check input and output shapes\n",
    "test_autoencoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, epochs=5, patience=2):\n",
    "    model.train()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=patience, verbose=True)\n",
    "    best_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for data in train_loader:\n",
    "            inputs, _ = data if len(data) == 2 else (data, data)  # Handle data without labels\n",
    "            inputs = inputs.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)  # Direct output from the model, no unpacking needed\n",
    "            loss = criterion(outputs, inputs)  # Reconstruction loss only\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}')\n",
    "        \n",
    "        scheduler.step(avg_loss)\n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "        \n",
    "        if epochs_no_improve == patience:\n",
    "            print('Early stopping triggered')\n",
    "            break\n",
    "\n",
    "    print('Training complete')\n",
    "\n",
    "# Example usage\n",
    "model = ConvSequenceAutoencoder()  # Assuming model is already defined and includes sparsity loss\n",
    "optimizer = Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Ensure train_loader is defined and properly set up\n",
    "train(model, train_loader, criterion, optimizer, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluate_model_and_plot(model, test_loader, threshold, device='cuda'):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    reconstruction_errors = []\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            # Ensure only reconstructed outputs are used, not the sparsity loss\n",
    "            reconstructed = model(inputs)  # Assuming model outputs (reconstruction, sparsity_loss)\n",
    "            reconstructed = reconstructed.to(device)\n",
    "            \n",
    "            # Calculate MSE for each image in the batch\n",
    "            mse = ((reconstructed - inputs) ** 2).mean(dim=[1, 2, 3])  # Calculate mean over channel, height, and width dimensions\n",
    "            \n",
    "            reconstruction_errors.append(mse.cpu().numpy())  # Store errors for further analysis\n",
    "            # Thresholding the MSE to make predictions, e.g., for anomaly detection\n",
    "            pred = (mse > threshold).int()\n",
    "            predictions.extend(pred.cpu().numpy())  # Store predictions\n",
    "            true_labels.extend(labels.cpu().numpy())  # Store true labels\n",
    "    \n",
    "    # Convert list of arrays to one large array\n",
    "    reconstruction_errors = np.concatenate(reconstruction_errors)\n",
    "    \n",
    "    error_dict = {}\n",
    "    unique_labels = np.unique(true_labels)\n",
    "    for label in unique_labels:\n",
    "        error_dict[label] = reconstruction_errors[np.array(true_labels) == label]\n",
    "\n",
    "    # Now plot histograms for each pair of interest\n",
    "    class_0_errors = error_dict[unique_labels[0]]\n",
    "    for i in range(1, len(unique_labels)):\n",
    "        class_i_errors = error_dict[unique_labels[i]]\n",
    "        if class_i_errors.size > 0 and class_0_errors.size > 0:\n",
    "            plt.figure(figsize=(8, 5))\n",
    "            plot_histogram(\n",
    "                class_i_errors, class_0_errors, threshold, \n",
    "                f'Label {unique_labels[i]}', f'Benign', \n",
    "                f'Label {unique_labels[i]} vs Benign'\n",
    "            )\n",
    "\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    print(f'Accuracy: {accuracy*100:.2f}%')\n",
    "\n",
    "    return accuracy, error_dict\n",
    "\n",
    "def plot_histogram(class1_errors, class2_errors, threshold, class1_label, class2_label, title):\n",
    "    max_error = max(np.max(class1_errors), np.max(class2_errors), threshold)\n",
    "    bins_range = (0, max_error)\n",
    "\n",
    "    plt.hist(class1_errors, bins=20, alpha=0.5, label=class1_label, color='blue', range=bins_range)\n",
    "    plt.hist(class2_errors, bins=20, alpha=0.5, label=class2_label, color='green', range=bins_range)\n",
    "\n",
    "    plt.axvline(x=threshold, color='red', linestyle='--', label=f'Threshold = {threshold:.2f}')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Reconstruction Error')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(title)\n",
    "    plt.xlim(left=0)\n",
    "    plt.show()\n",
    "\n",
    "# Assuming 'model', 'test_loader', 'device', and 'threshold' are already defined\n",
    "accuracy, error_dict = evaluate_model_and_plot(model, test_loader, threshold= int(1e17), device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize sample inputs and reconstructed output side by side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_reconstructions2(model, test_loader_2d, num_images=100):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    images_displayed = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader_2d:\n",
    "            if images_displayed >= num_images:\n",
    "                break  # Stop after displaying the specified number of images\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Assuming inputs and outputs are now [batch_size, channels, height, width]\n",
    "            for original, reconstructed, label in zip(inputs, outputs, labels):\n",
    "                if images_displayed >= num_images:\n",
    "                    break\n",
    "\n",
    "                label_text = 'Malware' if label.item() == 1 else 'Benign'\n",
    "                \n",
    "                # Remove the channel dimension for visualization\n",
    "                original = original.squeeze().cpu().numpy()  # Squeeze here\n",
    "                reconstructed = reconstructed.squeeze().cpu().numpy()  # And here\n",
    "                \n",
    "                plt.figure(figsize=(6, 3))\n",
    "                \n",
    "                # Plot the original image with label\n",
    "                plt.subplot(1, 2, 1)\n",
    "                plt.imshow(original, cmap='gray')  # Adjusted\n",
    "                plt.title(f'Original ({label_text})')\n",
    "                plt.axis('off')\n",
    "                \n",
    "                # Plot the reconstructed image\n",
    "                plt.subplot(1, 2, 2)\n",
    "                plt.imshow(reconstructed, cmap='gray')  # Adjusted\n",
    "                plt.title(f'Reconstructed ({label_text})')\n",
    "                plt.axis('off')\n",
    "                \n",
    "                plt.show()\n",
    "                \n",
    "                images_displayed += 1\n",
    "\n",
    "import torch\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_reconstructions(model, test_loader, device='cuda', num_samples=5):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    sample_inputs, sample_recons = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, labels) in enumerate(test_loader):\n",
    "            if batch_idx >= num_samples:  # Only store num_samples of samples\n",
    "                break\n",
    "            inputs = inputs.to(device)\n",
    "            reconstructed, _ = model(inputs)  # Assuming model outputs (reconstruction, sparsity_loss)\n",
    "            sample_inputs.append(inputs.cpu())\n",
    "            sample_recons.append(reconstructed.cpu())\n",
    "    \n",
    "    # Now, visualize the samples and their reconstructions\n",
    "    for index in range(num_samples):\n",
    "        plt.figure(figsize=(10, 4))\n",
    "\n",
    "        # Original Images\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.title('Original Images')\n",
    "        original_images = make_grid(sample_inputs[index], nrow=5, padding=2, normalize=True)\n",
    "        plt.imshow(original_images.permute(1, 2, 0))\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Reconstructed Images\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.title('Reconstructed Images')\n",
    "        recon_images = make_grid(sample_recons[index], nrow=5, padding=2, normalize=True)\n",
    "        plt.imshow(recon_images.permute(1, 2, 0))\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "# Example usage, after you have called your evaluate_model_and_plot method:\n",
    "visualize_reconstructions(model, test_loader, device='cuda', num_samples=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
